Present Absent
Model Fi\@M F@M|F,@M Fe@M

old new old new
catSeq 0.367 0.376 0.032 0.034
catSeqD 0.363 0.372 0.031 0.033
catSeqCorr 0.365 0.375 0.032 0.034
catSeqTG 0.366 0.374 0.032 0.033
catSeq-2RF, 0.383 0.396 0.047 0.054
catSeqD-2RFi 0.379 0.390 0.046 0.052
catSeqCor-2RF; | 0.382 0.393 0.045 0.051
catSeqTG-2RF 0.386 0.398 0.050 0.056

 

 

 

Table 6: Keyphrase prediction results on the KP20k
dataset with our new evaluation method.

Seq model using another RL algorithm which
only gives one reward for all generated keyphrases
without distinguishing present keyphrases and ab-
sent keyphrases. We use “catSeq-RF,” to de-
note such a method. As seen in Table 5, although
the performance of catSeq-RF; is competitive to
catSeq-2RF on predicting present keyphrases, it
yields an extremely poor performance on absent
keyphrase prediction. We analyze the cause as
follows. During the training process of catSeq-
RF, generating a correct present keyphrase or a
correct absent keyphrase leads to the same degree
of improvement in the return at every time step.
Since producing a correct present keyphrase is an
easier task, the model tends to generate present
keyphrases only.

Alternative reward function. We implement a
variant of our RL algorithm by replacing the adap-
tive RF, reward function with an F, score func-
tion (indicated with a suffix “-2F” in the result
table). By comparing the last two rows in Table 5,
we observe that our RF reward function slightly
outperforms the F reward function.

6.8 Analysis of New Evaluation Method

We extract name variations for all keyphrase la-
bels in the testing set of KP20k dataset, follow-
ing the methodology in Section 5. Our method
extracts at least one additional name variation for
14.1% of the ground-truth keyphrases. For these
enhanced keyphrases, the average number of name
variations extracted is 1.01. Among all extracted
name variations, 14.1% come from the acronym in
the ground-truth, 28.2% from the Wikipedia dis-
ambiguation pages, and the remaining 61.6% from
Wikipedia entity page titles.

We use our new evaluation method to evaluate
the performance of different keyphrase generation
models, and compare with the existing evaluation
method. Table 6 shows that for all generative mod-

els, the evaluation scores computed by our method
are higher than those computed by prior method.
This demonstrates that our proposed evaluation
successfully captures name variations of ground-
truth keyphrases generated by different models,
and can therefore evaluate the quality of generated
keyphrases in a more robust manner.

7 Conclusion and Future Work

In this work, we propose the first RL approach
to the task of keyphrase generation. In our RL
approach, we introduce an adaptive reward func-
tion RF, which encourages the model to generate
both sufficient and accurate keyphrases. Empirical
studies on real data demonstrate that our deep rein-
forced models consistently outperform the current
state-of-the-art models. In addition, we propose a
novel evaluation method which incorporates name
variations of the ground-truth keyphrases. As a
result, it can more robustly evaluate the quality
of generated keyphrases. One potential future di-
rection is to investigate the performance of other
encoder-decoder architectures on keyphrase gen-
eration such as Transformer (Vaswani et al., 2017)
with multi-head attention module (Li et al., 2018;
Zhang et al., 2018a). Another interesting direc-
tion is to apply our RL approach on the microblog
hashtag annotation problem (Wang et al., 2019;
Gong and Zhang, 2016; Zhang et al., 2018b).

Acknowledgments

The work described in this paper was partially
supported by the Research Grants Council of the
Hong Kong Special Administrative Region, China
(No. CUHK 14208815 of the General Research
Fund) and Meitu (No. 7010445). Lu Wang is
supported in part by National Science Foundation
through Grants ITS- 1566382 and IIS-1813341, and
by the Office of the Director of National Intel-
ligence (ODND), Intelligence Advanced Research
Projects Activity (IARPA), via contract # FA8650-
17-C-9116. The views and conclusions contained
herein are those of the authors and should not be
interpreted as necessarily representing the official
policies, either expressed or implied, of ODNI,
TARPA, or the U.S. Government. The U.S. Gov-
ernment is authorized to reproduce and distribute
reprints for governmental purposes notwithstand-
ing any copyright annotation therein. We would
like to thank Jiani Zhang, and the three anonymous
reviewers for their comments.

2171
6. Sub-Query Generation

 

s-evaly(S,|q,k, &) = Vin [eval(Rs,|q,*)], (6.2)

where k is the number of top suggestions to be evaluated (the suggestion eval-
uation cutoff), « is the number of top documents to be evaluated for each sug-
gestion (the retrieval evaluation cutoff), Rs, is the ranking produced for the
query suggestion s; by a reference retrieval system, and WV is a summary statistic.
In Section 6.4.2, we report both the maximum (VY = “max”) and the average
(Y = “avg”) retrieval performance attained by the top & suggestions. For in-
stance, with nDCG (Equation (2.51)) used as a document ranking evaluation
metric eval(e), UY = “max”, k = 1, and « = 10, we can instantiate Equation (6.2)
in order to have s-nDCGyx@1,10 as a query suggestion evaluation metric. This
metric quantifies the effectiveness (in terms of the nDCG@10 performance of
the resulting document ranking) of a query suggestion mechanism at providing
a single suggestion. Such a suggestion could be used, e.g., for automatically re-
formulating the initial query. With VY = “avg”, k = 8, and k = 10, we can
have s-nDCG,yg@8,10, which models a typical application of query suggestion,
as seen on the search box of modern web search engines. Note that both the
W = “max” and VW = “avg” summary statistics consider the top k suggestions as
an unordered set, regardless of how these suggestions were ranked with respect to
each other. Although rank-based summary statistics are certainly possible, this
would imply assuming that users prefer the top ranked suggestion over the others.
Since, to the best of our knowledge, there is no empirical study supporting this
assumption, we opted for a set-based evaluation in our investigations.

The query suggestion evaluation metrics generated by Equation (6.2) assume
that the query gq unambiguously expresses the user’s information need. Indeed,
both qg and the suggestion s; are evaluated with respect to the information need
represented by g. In practice, however, the queries submitted to a web search
engine are often ambiguous (Song et al., 2009), with the same query being used
by different search users to represent different information needs (Sparck-Jones
et al., 2007). In this situation, providing a diverse list of suggestions could not

only help the users better specify their need, but would also enable an effec-

132
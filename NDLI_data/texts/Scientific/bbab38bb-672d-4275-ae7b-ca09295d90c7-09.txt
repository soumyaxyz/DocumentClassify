Ad hoc retrieval via entity linking and semantic similarity 559

where SemRel(x, y) is the value of semantic relatedness between two concepts associated with
x and y. Now, the probability of P(Qq,|Col) is defined based on the document probabilities
and collection statistics as follows:

Dajecot Pseim(Qq;|Da)

P(Qq,|Col) = Gal

(6)

Returning to our example, the score generated for the document depicted in Fig. 2 for the
query ‘Journalism’ is equal to the probability of assigning the value of 1 to the Journalism
node, given that the value of | is assigned to four nodes ‘Knight Ridder, ‘William Dean
Singleton,’ “Newspaper, and ‘Star-News.’ This probability is defined using the features
estimated over the following four sets: {*‘Knight Ridder, ‘Journalism’}, {‘William Dean
Singleton,’ ‘Journalism’}, { ‘Newspaper, ‘Journalism’ }, and {‘Star-News,’ ‘Journalism’}.
The values of features are defined based on semantic similarities found by any semantic
analysis systems.

In Sect. 4, we will see how the results generated by SELM can be integrated with traditional
keyword-based retrieval models for generating better results.

4 Integration module

Recalling Fig. 1, the results generated by SELM are fed into the integration module in order
to be interpolated with the results obtained from keyword-based systems. As we will show
later in the experimental results section, while SELM and other retrieval models can produce
overlapping results, in many cases a subset of their relevant and correct results is distinct
and non-overlapping. For this reason, the interpolation of these models can benefit from the
correctly retrieved documents of each model and hence lead to improved performance.

Integrating different language models for finding a combined similarity score has been a
topic of research in the recent years. In [3], a model is proposed to integrate language model
9p, which is a language model based on the term dependency assumption, and 6,, which is
a language model based on non-dependency assumption in the following form:

P(qid) =|] Pail)
i=1

=] [lP@. eld) + PGi, 8pld))
i=l

n (7)
= [[leq@. |) p@pl|d) + P@i. |d)p@pld)]
i=l

=| [IP i. Dao + PGi. IdA051

i=1

In this mode, Ag, and Ag, are the probability of choosing dependency or non-dependency
models given a document. The last line reformulates the model as a mixture model where
op and rg, are mixture weights and needed to be estimated. For integrating SELM and
other language models, we follow a similar approach but with important differences:

Score(d, q) = Ax wScorex w(d, q) + AseimScoreseim(d, q) (8)

a Springer